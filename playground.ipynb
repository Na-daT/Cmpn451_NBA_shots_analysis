{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a playground for performing experiments before implementing them in the main code using pyspark for quick access"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(210072, 16)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "\n",
    "csv_path = \"./NBA shot log 16-17-regular season/Shot data/\"\n",
    "\n",
    "# read all csvs in the directory\n",
    "df = pd.concat([pd.read_csv(f) for f in glob.glob(csv_path + \"*.csv\")], ignore_index=True)\n",
    "\n",
    "# Print the number of rows and columns\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jump Shot                     94078\n",
      "Layup                         15826\n",
      "Pullup Jump Shot              14671\n",
      "Driving Layup                 13433\n",
      "Floating Jump Shot             4522\n",
      "Step Back Jump Shot            4454\n",
      "Hook Shot                      4279\n",
      "Tip Layup Shot                 3957\n",
      "Cutting Layup Shot             3800\n",
      "Running Layup                  3587\n",
      "Turnaround Jump Shot           3245\n",
      "Driving Floating Jump Shot     3199\n",
      "Fadeaway Jumper                2780\n",
      "Dunk                           2755\n",
      "Putback Layup                  2263\n",
      "Driving Finger Roll Layup      2261\n",
      "Cutting Dunk Shot              2118\n",
      "Reverse Layup                  1849\n",
      "Turnaround Hook Shot           1828\n",
      "Running Jump Shot              1824\n",
      "Driving Reverse Layup          1688\n",
      "Jump Bank Shot                 1467\n",
      "Alley Oop Dunk                 1440\n",
      "Driving Dunk                   1411\n",
      "Driving Hook Shot              1296\n",
      "Running Dunk                   1278\n",
      "Name: shot type, dtype: int64\n",
      "26\n",
      "195309\n"
     ]
    }
   ],
   "source": [
    "# print the number of shot types in the dataset that have a frequency of 1000 or more   \n",
    "print(df['shot type'].value_counts()[df['shot type'].value_counts() >= 1000])\n",
    "# print their count\n",
    "print(df['shot type'].value_counts()[df['shot type'].value_counts() >= 1000].count())\n",
    "# print their sum\n",
    "print(df['shot type'].value_counts()[df['shot type'].value_counts() >= 1000].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(162607, 16)\n"
     ]
    }
   ],
   "source": [
    "# get the 10 most frequent shot types\n",
    "shot_type = df['shot type'].value_counts().head(10)\n",
    "\n",
    "# only keep shot types that are in the top 10\n",
    "#df = df[df['shot type'].isin(shot_type.index)]\n",
    "\n",
    "# encode the shot type as an integer\n",
    "#df['shot type'] = df['shot type'].astype('category').cat.codes\n",
    "\n",
    "# print the number of rows and columns\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "def normalize_timer():\n",
    "    for f in glob.glob(csv_path + \"*.csv\"):\n",
    "        temp = pd.read_csv(f) \n",
    "\n",
    "        temp['time'] = temp['time'].str.split(':').apply(lambda x: int(x[0]) * 60 + int(x[1]))\n",
    "        temp['time'] = temp['time'] + (temp['quarter'] - 1) * 720\n",
    "        # divide time by 2880 to normalize it\n",
    "        temp['time'] = temp['time'] / 2880\n",
    "\n",
    "        # save csv\n",
    "        temp.to_csv(f, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['#Date/Time of Update: 2017-05-09 4:34:01 PM', '#Player ID',\n",
      "       '#LastName', '#FirstName', '#Jersey Num', '#Position', '#Height',\n",
      "       '#Weight', '#Birth Date', '#Age', '#Birth City', '#Birth Country',\n",
      "       '#Rookie', '#Team ID', '#Team Abbr', '#Team City', '#Team Name',\n",
      "       '#GamesPlayed', '#Fg2PtAtt', '#Fg2PtMade', '#Fg3PtAtt', '#Fg3PtMade',\n",
      "       '#FtAtt', '#FtMade'],\n",
      "      dtype='object')\n",
      "Index(['#LastName', '#FirstName', '#Height', '#Weight', '#Birth Date', '#Age',\n",
      "       '#Rookie', '#GamesPlayed', '#Fg2PtAtt', '#Fg2PtMade', '#Fg3PtAtt',\n",
      "       '#Fg3PtMade', '#FtAtt', '#FtMade'],\n",
      "      dtype='object')\n",
      "Index(['#Height', '#Weight', '#Birth Date', '#Age', '#Rookie', '#GamesPlayed',\n",
      "       '#Fg2PtAtt', '#Fg2PtMade', '#Fg3PtAtt', '#Fg3PtMade', '#FtAtt',\n",
      "       '#FtMade', 'shoot player'],\n",
      "      dtype='object')\n",
      "Index(['self previous shot', 'player position', 'home game', 'location x',\n",
      "       'opponent previous shot', 'home team', 'shot type', 'points',\n",
      "       'away team', 'location y', 'time', 'date', 'shoot player',\n",
      "       'time from last shot', 'quarter', 'current shot outcome', '#Height',\n",
      "       '#Weight', '#Birth Date', '#Age', '#Rookie', '#GamesPlayed',\n",
      "       '#Fg2PtAtt', '#Fg2PtMade', '#Fg3PtAtt', '#Fg3PtMade', '#FtAtt',\n",
      "       '#FtMade'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# read player data\n",
    "df_player = pd.read_csv(\"./NBA shot log 16-17-regular season/Player Regular 16-17 Stats.csv\")\n",
    "\n",
    "\n",
    "\n",
    "print(df_player.columns)\n",
    "# remove the columns that are not needed [#Date/Time of Update: 2017-05-09 4:34:01 PM, #Player ID, #Jersey Num, #Birth Date, #Birth City, #Birth Couuntry, #Team ID\n",
    "#                                         #Team Abbr, #Team City, #Team Name]\n",
    "df_player = df_player.drop(['#Date/Time of Update: 2017-05-09 4:34:01 PM', '#Player ID', '#Jersey Num', '#Birth City', '#Birth Country', '#Team ID', '#Team Abbr', '#Team City', '#Team Name', '#Position'], axis=1)\n",
    "print(df_player.columns)\n",
    "\n",
    "# combine First Name and Last Name to create a new column called Player Name\n",
    "df_player['shoot player'] = df_player['#FirstName'] + \" \" + df_player['#LastName']\n",
    "df_player = df_player.drop(['#FirstName', '#LastName'], axis=1)\n",
    "print(df_player.columns)\n",
    "\n",
    "# connect df_player and df[0]\n",
    "df_merged = pd.merge(df, df_player, on='shoot player', how='inner')\n",
    "df_merged.to_csv(\"output/Standard/Single File/merged.csv\", index=False)\n",
    "print(df_merged.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Muhab\\AppData\\Local\\Temp\\ipykernel_1984\\2095260306.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_merged_test['accuracy'][df_merged_test['points'] == 0] = df_merged_test['#Fg2PtMade'] / df_merged_test['#Fg2PtAtt']\n",
      "C:\\Users\\Muhab\\AppData\\Local\\Temp\\ipykernel_1984\\2095260306.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_merged_test['accuracy'][df_merged_test['points'] == 1] = df_merged_test['#Fg3PtMade'] / df_merged_test['#Fg3PtAtt']\n"
     ]
    }
   ],
   "source": [
    "df_merged_test = df_merged\n",
    "# print unique values in self previous shot\n",
    "columns_to_print = ['self previous shot', 'player position', 'home game', 'opponent previous shot', 'home team', 'points', 'time from last shot', 'quarter', 'current shot outcome', '#Position',\n",
    "       '#Height', '#Weight', '#Age', '#Rookie', '#GamesPlayed', '#Fg2PtAtt',\n",
    "       '#Fg2PtMade', '#Fg3PtAtt', '#Fg3PtMade', '#FtAtt', '#FtMade']\n",
    "\n",
    "\n",
    "\n",
    "# Map poitns from [2, 3] to [0, 1]\n",
    "df_merged_test['points'] = df_merged_test['points'].map({2: 0, 3: 1})\n",
    "\n",
    "# for players with points = 2 add an extra column called accuracy for 2 pointers adn for players with points = 3 add an extra column called accuracy for 3 pointers\n",
    "df_merged_test['accuracy'] = 0\n",
    "df_merged_test['accuracy'][df_merged_test['points'] == 0] = df_merged_test['#Fg2PtMade'] / df_merged_test['#Fg2PtAtt']\n",
    "df_merged_test['accuracy'][df_merged_test['points'] == 1] = df_merged_test['#Fg3PtMade'] / df_merged_test['#Fg3PtAtt']\n",
    "\n",
    "# Drop players with 0 attempts in Fg2PtAtt, Fg3PtAtt, FtAtt\n",
    "df_merged_test = df_merged_test[df_merged_test['#Fg2PtAtt'] != 0]\n",
    "df_merged_test = df_merged_test[df_merged_test['#Fg3PtAtt'] != 0]\n",
    "df_merged_test = df_merged_test[df_merged_test['#FtAtt'] != 0]\n",
    "\n",
    "# Drop Fg2PtAtt, Fg2PtMade, Fg3PtAtt, Fg3PtMade, FtAtt, FtMade\n",
    "df_merged_test = df_merged_test.drop(['#Fg2PtAtt', '#Fg2PtMade', '#Fg3PtAtt', '#Fg3PtMade', '#FtAtt', '#FtMade'], axis=1)\n",
    "# Drop irrelevant columns\n",
    "df_merged_test = df_merged_test.drop(['date','#Birth Date', 'away team', 'home team', 'shoot player', 'quarter', 'shot type'], axis=1)\n",
    "\n",
    "# Convert height from feet-inches to inches\n",
    "# height map\n",
    "height_map = {'5\\'4\\\"': 64, '5\\'9\\\"': 69, '5\\'10\\\"': 70, '5\\'11\\\"': 71,\n",
    "       '6\\'0\\\"': 72, '6\\'1\\\"': 73, '6\\'2\\\"': 74, '6\\'3\\\"': 75, '6\\'4\\\"': 76, '6\\'5\\\"': 77, '6\\'6\\\"': 78, '6\\'7\\\"': 79, '6\\'8\\\"': 80,\n",
    "       '6\\'9\\\"': 81, '6\\'10\\\"': 82, '6\\'11\\\"': 83, '7\\'0\\\"': 84, '7\\'1\\\"': 85, '7\\'2\\\"': 86, '7\\'3\\\"': 87}\n",
    "# convert height to inches using height_map\n",
    "df_merged_test['#Height'] = df_merged_test['#Height'].map(height_map)\n",
    "# replace height nans with the mean\n",
    "df_merged_test['#Height'] = df_merged_test['#Height'].fillna(round(df_merged_test['#Height'].mean()))\n",
    "# Normalize height subtracting the min and dividing by the range\n",
    "df_merged_test['#Height'] = (df_merged_test['#Height'] - df_merged_test['#Height'].min()) / (df_merged_test['#Height'].max() - df_merged_test['#Height'].min())\n",
    "\n",
    "# Fill age nans with the mean\n",
    "df_merged_test['#Age'] = df_merged_test['#Age'].fillna(round(df_merged_test['#Age'].mean()))\n",
    "# Normalize age using z-score\n",
    "df_merged_test['#Age'] = (df_merged_test['#Age'] - df_merged_test['#Age'].mean()) / df_merged_test['#Age'].std()\n",
    "# Fill weight nans with the mean\n",
    "df_merged_test['#Weight'] = df_merged_test['#Weight'].fillna(round(df_merged_test['#Weight'].mean()))\n",
    "# Normalize weight using z-score\n",
    "df_merged_test['#Weight'] = (df_merged_test['#Weight'] - df_merged_test['#Weight'].mean()) / df_merged_test['#Weight'].std()\n",
    "\n",
    "# Convert rookie to 0 and 1\n",
    "df_merged_test['#Rookie'] = df_merged_test['#Rookie'].map({'N': 0, 'Y': 1})\n",
    "\n",
    "# drop nans from rows with location x as null\n",
    "# reason, very few they represent less than 0.1% of our dataset and have a null y location as well\n",
    "df_merged_test = df_merged_test.dropna(subset=['location x']) \n",
    "# change the columns with location x > 470 to 940 - location x\n",
    "df_merged_test.loc[df_merged_test['location x'] > 470, 'location x'] = 940 - df_merged_test['location x']\n",
    "\n",
    "# normalize location x and location y\n",
    "df_merged_test['location x'] = df_merged_test['location x'] / 470 # half court width\n",
    "df_merged_test['location y'] = df_merged_test['location y'] / 500 # court length\n",
    "\n",
    "# normalize games played z-score\n",
    "df_merged_test['#GamesPlayed'] = (df_merged_test['#GamesPlayed'] - df_merged_test['#GamesPlayed'].mean()) / df_merged_test['#GamesPlayed'].std() \n",
    "\n",
    "\n",
    "# Map player position from ['SF' 'C' 'SG' 'PG' 'PF' 'G' 'F'] to [0, 1, 2, 3, 4 ,5, 6]\n",
    "df_merged_test['player position'] = df_merged_test['player position'].map({'SF': 0, 'C': 1, 'SG': 2, 'PG': 3, 'PF': 4, 'G': 5, 'F': 6})\n",
    "\n",
    "# Drop nulls in self previous shot and opponent previous shot\n",
    "df_merged_test = df_merged_test.dropna(subset=['self previous shot', 'opponent previous shot'])\n",
    "\n",
    "# Map current shot outcome from ['MISSED' 'BLOCKED' 'SCORED'] to [0, 0, 1]\n",
    "df_merged_test['self previous shot'] = df_merged_test['self previous shot'].map({'MISSED': 0, 'BLOCKED': 0, 'SCORED': 1})\n",
    "df_merged_test['opponent previous shot'] = df_merged_test['opponent previous shot'].map({'MISSED': 0, 'BLOCKED': 0, 'SCORED': 1})\n",
    "df_merged_test['current shot outcome'] = df_merged_test['current shot outcome'].map({'MISSED': 0, 'BLOCKED': 0, 'SCORED': 1})\n",
    "# for home game map home/away to 1/0\n",
    "df_merged_test['home game'] = df_merged_test['home game'].map({'Yes': 1, 'No': 0})\n",
    "df_merged_test = df_merged_test.drop(['home game'], axis=1)\n",
    "# drop previous shots\n",
    "df_merged_test = df_merged_test.drop(['self previous shot', 'opponent previous shot'], axis=1)\n",
    "\n",
    "df_merged_test.to_csv(\"output/Standard/Single File/merged_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['player position', 'location x', 'points', 'location y', 'time',\n",
      "       'current shot outcome', '#Height', '#Weight', '#Age', '#Rookie',\n",
      "       '#GamesPlayed', 'accuracy'],\n",
      "      dtype='object')\n",
      "current shot outcome    1.000000\n",
      "accuracy                0.112709\n",
      "#Weight                 0.016465\n",
      "#GamesPlayed            0.016219\n",
      "#Age                    0.011761\n",
      "#Height                 0.008771\n",
      "location y              0.002932\n",
      "player position        -0.012777\n",
      "#Rookie                -0.019308\n",
      "time                   -0.023336\n",
      "points                 -0.084325\n",
      "location x             -0.099415\n",
      "Name: current shot outcome, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# print nulls per column in df_player\n",
    "df_merged_test['time from last shot'] = df_merged_test['time from last shot'].fillna(round(df_merged_test['time from last shot'].mean()))\n",
    "\n",
    "# drop time from last shot\n",
    "df_merged_test = df_merged_test.drop(['time from last shot'], axis=1)\n",
    "\n",
    "# print first 10 rows with time from last shot as nan\n",
    "#print(df[df['time from last shot'].isnull()].head(10))\n",
    "corr = df_merged_test.corr()\n",
    "print(df_merged_test.columns)\n",
    "# print correlation with \"curent shot outcome\"\n",
    "print(corr['current shot outcome'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   player position  location x  points  location y      time  \\\n",
      "1                0    0.593617       1       0.260  0.066319   \n",
      "2                0    0.123404       0       0.550  0.455903   \n",
      "3                0    0.153191       1       0.950  0.521528   \n",
      "4                0    0.529787       1       0.200  0.600694   \n",
      "5                0    0.529787       0       0.362  0.635069   \n",
      "\n",
      "   current shot outcome   #Height   #Weight      #Age  #Rookie  #GamesPlayed  \\\n",
      "1                     0  0.565217 -0.602271  0.017925        0      0.316118   \n",
      "2                     0  0.565217 -0.602271  0.017925        0      0.316118   \n",
      "3                     0  0.565217 -0.602271  0.017925        0      0.316118   \n",
      "4                     1  0.565217 -0.602271  0.017925        0      0.316118   \n",
      "5                     0  0.565217 -0.602271  0.017925        0      0.316118   \n",
      "\n",
      "   accuracy  \n",
      "1  0.345865  \n",
      "2  0.445175  \n",
      "3  0.345865  \n",
      "4  0.345865  \n",
      "5  0.445175  \n",
      "MSE: 0.40306398700512786\n",
      "Accuracy: 0.5969360129948721\n",
      "R2 Score: -0.6735147504722496\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# train a model to predict current shot outcome\n",
    "# logistic regression\n",
    "# Split data into train and test\n",
    "# display first 5 rows of df_merged_test\n",
    "print(df_merged_test.head(5))\n",
    "X = df_merged_test.drop(['current shot outcome'], axis=1)\n",
    "y = df_merged_test['current shot outcome']\n",
    "import sklearn.model_selection as model_selection\n",
    "\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import accuracy_score, r2_score\n",
    "\n",
    "\n",
    "# Train model\n",
    "model = LogisticRegression(random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"MSE:\", mean_squared_error(y_test, y_pred))\n",
    "# Print accuracy\n",
    "print(\"Accuracy:\", model.score(X_test, y_test))\n",
    "# display r2 score\n",
    "print(\"R2 Score:\", r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.003042 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[1]\tvalid_0's l2: 0.240229\tvalid_0's l1: 0.481638\n",
      "Training until validation scores don't improve for 5 rounds\n",
      "[2]\tvalid_0's l2: 0.239534\tvalid_0's l1: 0.480895\n",
      "[3]\tvalid_0's l2: 0.23891\tvalid_0's l1: 0.480192\n",
      "[4]\tvalid_0's l2: 0.238341\tvalid_0's l1: 0.47952\n",
      "[5]\tvalid_0's l2: 0.23787\tvalid_0's l1: 0.47894\n",
      "[6]\tvalid_0's l2: 0.237378\tvalid_0's l1: 0.478308\n",
      "[7]\tvalid_0's l2: 0.236999\tvalid_0's l1: 0.477791\n",
      "[8]\tvalid_0's l2: 0.2366\tvalid_0's l1: 0.477226\n",
      "[9]\tvalid_0's l2: 0.236231\tvalid_0's l1: 0.476678\n",
      "[10]\tvalid_0's l2: 0.235899\tvalid_0's l1: 0.476164\n",
      "[11]\tvalid_0's l2: 0.235632\tvalid_0's l1: 0.475726\n",
      "[12]\tvalid_0's l2: 0.235383\tvalid_0's l1: 0.475295\n",
      "[13]\tvalid_0's l2: 0.235159\tvalid_0's l1: 0.474886\n",
      "[14]\tvalid_0's l2: 0.23493\tvalid_0's l1: 0.474447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Muhab\\anaconda3\\lib\\site-packages\\lightgbm\\engine.py:181: UserWarning: 'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. Pass 'early_stopping()' callback via 'callbacks' argument instead.\n",
      "  _log_warning(\"'early_stopping_rounds' argument is deprecated and will be removed in a future release of LightGBM. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15]\tvalid_0's l2: 0.234719\tvalid_0's l1: 0.474027\n",
      "[16]\tvalid_0's l2: 0.234548\tvalid_0's l1: 0.473688\n",
      "[17]\tvalid_0's l2: 0.234381\tvalid_0's l1: 0.473341\n",
      "[18]\tvalid_0's l2: 0.234213\tvalid_0's l1: 0.472981\n",
      "[19]\tvalid_0's l2: 0.234062\tvalid_0's l1: 0.47263\n",
      "[20]\tvalid_0's l2: 0.233906\tvalid_0's l1: 0.472281\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[20]\tvalid_0's l2: 0.233906\tvalid_0's l1: 0.472281\n",
      "Starting predicting...\n",
      "The rmse of prediction is: 0.48363800904937687\n",
      "Feature importances: [9, 168, 17, 150, 52, 16, 26, 23, 2, 10, 127]\n",
      "Accuracy: 0.6183074816065229\n",
      "R2 score: -0.5847807799019709\n"
     ]
    }
   ],
   "source": [
    "# LightGBM\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "# Create dataset for lightgbm\n",
    "lgb_train = lgb.Dataset(X_train, y_train)\n",
    "lgb_eval = lgb.Dataset(X_test, y_test, reference=lgb_train)\n",
    "\n",
    "# predict using lightgbm\n",
    "\n",
    "# specify your configurations as a dict\n",
    "params = {\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'l2', 'l1'},\n",
    "    'num_leaves': 31,\n",
    "    'learning_rate': 0.05,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.8,\n",
    "    'bagging_freq': 5,\n",
    "    'verbose': 0,\n",
    "    'num_threads': 4\n",
    "}\n",
    "\n",
    "print('Starting training...')\n",
    "# train\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=20,\n",
    "                valid_sets=lgb_eval,\n",
    "                early_stopping_rounds=5)\n",
    "\n",
    "#print('Saving model...')\n",
    "\n",
    "# save model to file\n",
    "\n",
    "#gbm.save_model('model.txt')\n",
    "\n",
    "print('Starting predicting...')\n",
    "# predict\n",
    "y_pred = gbm.predict(X_test, num_iteration=gbm.best_iteration)\n",
    "# eval\n",
    "print('The rmse of prediction is:', mean_squared_error(y_test, y_pred) ** 0.5)\n",
    "\n",
    "# feature importances\n",
    "print('Feature importances:', list(gbm.feature_importance()))\n",
    "\n",
    "# display accuracy gbm\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred.round()))\n",
    "# print r2 score\n",
    "print(\"R2 score:\", r2_score(y_test, y_pred.round()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:41:54] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-07593ffd91cd9da33-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:767: \n",
      "Parameters: { \"silent\" } are not used.\n",
      "\n",
      "[0]\teval-rmse:0.49709\ttrain-rmse:0.49701\n",
      "[1]\teval-rmse:0.49446\ttrain-rmse:0.49432\n",
      "[2]\teval-rmse:0.49255\ttrain-rmse:0.49231\n",
      "[3]\teval-rmse:0.49081\ttrain-rmse:0.49045\n",
      "[4]\teval-rmse:0.48943\ttrain-rmse:0.48896\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Muhab\\anaconda3\\lib\\site-packages\\xgboost\\core.py:617: FutureWarning: Pass `evals` as keyword args.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5]\teval-rmse:0.48818\ttrain-rmse:0.48763\n",
      "[6]\teval-rmse:0.48734\ttrain-rmse:0.48672\n",
      "[7]\teval-rmse:0.48659\ttrain-rmse:0.48589\n",
      "[8]\teval-rmse:0.48584\ttrain-rmse:0.48506\n",
      "[9]\teval-rmse:0.48538\ttrain-rmse:0.48458\n",
      "[10]\teval-rmse:0.48487\ttrain-rmse:0.48396\n",
      "[11]\teval-rmse:0.48448\ttrain-rmse:0.48346\n",
      "[12]\teval-rmse:0.48408\ttrain-rmse:0.48299\n",
      "[13]\teval-rmse:0.48383\ttrain-rmse:0.48262\n",
      "[14]\teval-rmse:0.48362\ttrain-rmse:0.48233\n",
      "[15]\teval-rmse:0.48342\ttrain-rmse:0.48209\n",
      "[16]\teval-rmse:0.48330\ttrain-rmse:0.48189\n",
      "[17]\teval-rmse:0.48314\ttrain-rmse:0.48166\n",
      "[18]\teval-rmse:0.48305\ttrain-rmse:0.48149\n",
      "[19]\teval-rmse:0.48290\ttrain-rmse:0.48127\n",
      "[20]\teval-rmse:0.48280\ttrain-rmse:0.48111\n",
      "[21]\teval-rmse:0.48272\ttrain-rmse:0.48096\n",
      "[22]\teval-rmse:0.48266\ttrain-rmse:0.48081\n",
      "[23]\teval-rmse:0.48258\ttrain-rmse:0.48064\n",
      "[24]\teval-rmse:0.48255\ttrain-rmse:0.48050\n",
      "[25]\teval-rmse:0.48249\ttrain-rmse:0.48039\n",
      "[26]\teval-rmse:0.48245\ttrain-rmse:0.48026\n",
      "[27]\teval-rmse:0.48244\ttrain-rmse:0.48014\n",
      "[28]\teval-rmse:0.48242\ttrain-rmse:0.48005\n",
      "[29]\teval-rmse:0.48239\ttrain-rmse:0.47995\n",
      "[30]\teval-rmse:0.48237\ttrain-rmse:0.47985\n",
      "[31]\teval-rmse:0.48234\ttrain-rmse:0.47976\n",
      "[32]\teval-rmse:0.48232\ttrain-rmse:0.47966\n",
      "[33]\teval-rmse:0.48232\ttrain-rmse:0.47962\n",
      "[34]\teval-rmse:0.48229\ttrain-rmse:0.47954\n",
      "[35]\teval-rmse:0.48229\ttrain-rmse:0.47948\n",
      "[36]\teval-rmse:0.48228\ttrain-rmse:0.47943\n",
      "[37]\teval-rmse:0.48227\ttrain-rmse:0.47937\n",
      "[38]\teval-rmse:0.48226\ttrain-rmse:0.47927\n",
      "[39]\teval-rmse:0.48224\ttrain-rmse:0.47919\n",
      "[40]\teval-rmse:0.48222\ttrain-rmse:0.47913\n",
      "[41]\teval-rmse:0.48224\ttrain-rmse:0.47901\n",
      "[42]\teval-rmse:0.48222\ttrain-rmse:0.47899\n",
      "[43]\teval-rmse:0.48225\ttrain-rmse:0.47888\n",
      "[44]\teval-rmse:0.48225\ttrain-rmse:0.47874\n",
      "[45]\teval-rmse:0.48223\ttrain-rmse:0.47867\n",
      "[46]\teval-rmse:0.48223\ttrain-rmse:0.47859\n",
      "[47]\teval-rmse:0.48224\ttrain-rmse:0.47853\n",
      "[48]\teval-rmse:0.48225\ttrain-rmse:0.47849\n",
      "[49]\teval-rmse:0.48224\ttrain-rmse:0.47844\n",
      "RMSE: 0.48224140429547013\n",
      "Accuracy: 0.6198999904449469\n",
      "R2 score: -0.5781687105599231\n"
     ]
    }
   ],
   "source": [
    "# use xgboost\n",
    "import xgboost as xgb\n",
    "\n",
    "# specify parameters via map\n",
    "\n",
    "params = {\n",
    "    'booster': 'gbtree',\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'rmse',\n",
    "    'eta': 0.1,\n",
    "    'max_depth': 6,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'silent': 1,\n",
    "    'seed': 42,\n",
    "    'tree_method': 'auto'\n",
    "}\n",
    "\n",
    "num_round = 50\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n",
    "evallist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "bst = xgb.train(params, dtrain, num_round, evallist, early_stopping_rounds=10)\n",
    "\n",
    "# make prediction\n",
    "preds = bst.predict(dtest)\n",
    "\n",
    "# display accuracy xgboost\n",
    "# print rmse\n",
    "print(\"RMSE:\", mean_squared_error(y_test, preds) ** 0.5)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, preds.round()))\n",
    "print (\"R2 score:\", r2_score(y_test, preds.round()))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "1310c6520792fcb7b0d25c1401245ed3fb6ffb6ace4a4c81d480b3badb3c3aa5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
